{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJWHjAloWHNM"
   },
   "source": [
    "# Data Augmentation\n",
    "\n",
    "El proceso de Data Augmentation consiste en realizar diversas transformaciones sobre los datos de entrada con el objetivo de aportar variabilidad e incrementar el tamaño de mi conjunto de datos, partiendo de los datos ya existentes y etiquetados. Dichas transformaciones puede ser, como vimos en teoria, de distintos tipos, sin embargo, es necesario tener en cuenta solo utilizar las que sean coherentes con el problema puntual sobre el que estamos trabajando.\n",
    "\n",
    "Para este ejercicio vamos a trabajar con un dataset de imágenes de perros y gatos, el cual contiene 4000 imagenes a color, 2000 de perros y 2000 de gatos. Dichas imágenes ya se encuentran divididas en 3 carpetas correspondientes a entrenamiento, validación y testeo con 2000, 1000 y 1000 imágenes en cada una, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 34267,
     "status": "ok",
     "timestamp": 1729351276601,
     "user": {
      "displayName": "Juan Ignacio Cavalieri",
      "userId": "15252118238119694163"
     },
     "user_tz": 180
    },
    "id": "QCxrrCdVSKet"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchsummary'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18732/367164453.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorchsummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchsummary'"
     ]
    }
   ],
   "source": [
    "import os, random, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import torch, torchvision, torchmetrics, torchsummary\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T97WZY-xoLLT"
   },
   "source": [
    "## Visualización de los datos\n",
    "\n",
    "A partir de observar las distintas imágenes, podemos notar que no todas conservan las mismas dimensiones, por lo que será necesario realizar un redimensionamiento de forma tal que queden uniformes para un posible entrenamiento con capas convolucionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = os.getcwd()\n",
    "TRAIN_PATH = ROOT_PATH + \"/dataset/dog_cat/train/\"\n",
    "TEST_PATH = ROOT_PATH + \"/dataset/dog_cat/test/\"\n",
    "CAT_TRAIN_PATH = ROOT_PATH + \"/dataset/dog_cat/train/cats/\"\n",
    "DOG_TRAIN_PATH = ROOT_PATH + \"/dataset/dog_cat/train/dogs/\"\n",
    "CAT_TEST_PATH = ROOT_PATH + \"/dataset/dog_cat/test/cats/\"\n",
    "DOG_TEST_PATH = ROOT_PATH + \"/dataset/dog_cat/test/dogs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train_files = os.listdir(CAT_TRAIN_PATH)\n",
    "dog_train_files = os.listdir(DOG_TRAIN_PATH)\n",
    "cat_test_files = os.listdir(CAT_TEST_PATH)\n",
    "dog_test_files = os.listdir(DOG_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8fegZFilttF"
   },
   "source": [
    "## Utilizar los datos\n",
    "\n",
    "Para consumir los datos con nuestro modelo vamos a utilizar objetos de la clase DataLoader. Tambien, para poder cargar imágenes propias utilizamos la clase [`ImageFolder`](https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html?highlight=imagefolder#torchvision.datasets.ImageFolder), a la cual le pasamos el directorio donde se encuentran las imágenes a partir del cual infiere las clases dentro del dataset. Para mas información respecto a este punto ver [aquí](https://pytorch.org/vision/stable/generated/torchvision.datasets.DatasetFolder.html#torchvision.datasets.DatasetFolder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZGP0tYGxqH4"
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "class_names = ['cat', 'dog']\n",
    "width, height = 150, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dL2JlRBBVVjS"
   },
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(size=(width, height)),\n",
    "    torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "train_set = torchvision.datasets.ImageFolder(root=TRAIN_PATH, transform=transforms)\n",
    "valid_set = torchvision.datasets.ImageFolder(root=TEST_PATH, transform=transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int=1,\n",
    "            out_channels: int=3,\n",
    "            kernel_size: int=3,\n",
    "            stride: int=1,\n",
    "            padding: int=1,\n",
    "            padding_mode: str='zeros',\n",
    "            activation=nn.ReLU(),\n",
    "            pool_kernel_size: int=3,\n",
    "            pool_stride: int=1,\n",
    "            pool_padding: int=1\n",
    "    ):\n",
    "        super(ConvolutionalBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.padding_mode = padding_mode\n",
    "        self.activation = activation\n",
    "        self.pool_kernel_size = pool_kernel_size\n",
    "        self.pool_stride = pool_stride\n",
    "        self.pool_padding = pool_padding\n",
    "\n",
    "        # Check parameters consistency\n",
    "        if kernel_size % 2 == 0:\n",
    "            assert kernel_size == stride, f\"Conv: Stride {stride} must be equal to  even kernel size {kernel_size}.\"\n",
    "        else:\n",
    "            assert ((kernel_size-1) / 2 == padding) & stride == 1, f\"Conv: Invalid padding {padding} for the given kernel size {kernel_size}\"\n",
    "        if pool_kernel_size % 2 == 0:\n",
    "            assert pool_kernel_size == pool_stride, f\"Pooling: Stride {pool_stride} must be equal to even kernel size {pool_kernel_size}.\"\n",
    "        else:\n",
    "            assert ((pool_kernel_size-1) / 2 == pool_padding) & pool_stride == 1, f\"Pooling: Invalid padding {pool_padding} for the given kernel size {pool_kernel_size}\"\n",
    "\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, padding_mode=padding_mode),\n",
    "            activation,\n",
    "            nn.MaxPool2d(pool_kernel_size, pool_stride, pool_padding)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_block(x)\n",
    "\n",
    "    def getConvOutputShape(self, in_shape):\n",
    "        return (self.out_channels,\n",
    "                (in_shape[1] - self.kernel_size + 2*self.padding) // self.stride + 1,\n",
    "                (in_shape[2] - self.kernel_size + 2*self.padding) // self.stride + 1)\n",
    "\n",
    "    def getPoolOutputShape(self, in_shape):\n",
    "        return (self.out_channels,\n",
    "                (in_shape[1] - self.pool_kernel_size + 2*self.pool_padding) // self.pool_stride + 1,\n",
    "                (in_shape[2] - self.pool_kernel_size + 2*self.pool_padding) // self.pool_stride + 1)\n",
    "\n",
    "    def getOutputShape(self, in_shape):\n",
    "        conv_shape = self.getConvOutputShape(in_shape)\n",
    "        pool_shape = self.getPoolOutputShape(conv_shape)\n",
    "        return pool_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            conv_blocks: list,\n",
    "            image_shape: tuple=(1, 28, 28),\n",
    "            n_classes: int=10,\n",
    "            out_neurons: int=64,\n",
    "            activation=nn.ReLU(),\n",
    "            criterion=nn.CrossEntropyLoss(),\n",
    "            dropout_rate: float=0.5,\n",
    "            init_type: str='xavier',\n",
    "            device: str='cpu'\n",
    "    ):\n",
    "        super(CNN, self).__init__()\n",
    "        for conv_block in conv_blocks:\n",
    "            image_shape = conv_block.getOutputShape(image_shape)\n",
    "        self.out_shape = image_shape\n",
    "        self.in_neurons = self.out_shape[0] * self.out_shape[1] * self.out_shape[2]\n",
    "        self.out_neurons = out_neurons\n",
    "        self.n_classes = n_classes\n",
    "        self.activation = activation\n",
    "        self.criterion = criterion\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.init_type = init_type\n",
    "        self.device = device\n",
    "\n",
    "        # Define layers\n",
    "        self.conv_blocks = nn.ModuleList(conv_blocks)\n",
    "        self.fully_connected = nn.Sequential(\n",
    "                nn.Linear(self.in_neurons, out_neurons),\n",
    "                activation,\n",
    "                nn.Dropout(dropout_rate),\n",
    "                nn.Linear(out_neurons, n_classes)\n",
    "        )\n",
    "\n",
    "        # Initialize the parameters.\n",
    "        self.initialize_weights(init_type)\n",
    "\n",
    "        # Define the metrics.\n",
    "        self.metrics = {\n",
    "            'epochs': [], \n",
    "            'loss': {'train': [], 'eval': []}, \n",
    "            'accuracy': {'train': [], 'eval': []}, \n",
    "            'time': 0.0\n",
    "        }\n",
    "\n",
    "    def initialize_weights(self, init_type):\n",
    "        for layer in self.fully_connected:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                if init_type == 'xavier':\n",
    "                    nn.init.xavier_uniform_(layer.weight)\n",
    "                elif init_type == 'he':\n",
    "                    nn.init.kaiming_uniform_(layer.weight, nonlinearity='relu')\n",
    "                else:\n",
    "                    nn.init.normal_(layer.weight, mean=0, std=0.01)\n",
    "                if layer.bias is not None:\n",
    "                    nn.init.uniform_(layer.bias, a=0, b=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self.conv_blocks:\n",
    "            x = block(x)\n",
    "        x = x.view(-1, self.in_neurons)\n",
    "        return self.fully_connected(x)\n",
    "    \n",
    "    def trainBatch(self, inputs_batch, targets_batch, optimizer):\n",
    "        inputs_batch = inputs_batch.to(self.device)             # push inputs to GPU\n",
    "        targets_batch = targets_batch.to(self.device)           # push labels to GPU\n",
    "        predictions_batch = self.forward(inputs_batch)          # forward pass\n",
    "        loss = self.criterion(predictions_batch, targets_batch) # compute the training loss\n",
    "        optimizer.zero_grad()                                   # zero the gradients\n",
    "        loss.backward()                                         # backward pass\n",
    "        optimizer.step()                                        # update the parameters (weights and biases)\n",
    "        return loss.item()\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        predictions = self.forward(inputs)\n",
    "        _, predictions = torch.max(predictions.data, 1)\n",
    "        return predictions\n",
    "\n",
    "    def computeLoss(self, dataloader):\n",
    "        loss = 0.0\n",
    "        samples = 0\n",
    "        self.eval() # set the model to evaluation mode\n",
    "        for inputs_batch, targets_batch in dataloader:\n",
    "            with torch.no_grad():\n",
    "                inputs_batch = inputs_batch.to(self.device)                             # push inputs to GPU\n",
    "                targets_batch = targets_batch.to(self.device)                           # push labels to GPU\n",
    "                predictions_batch = self.forward(inputs_batch)                          # forward pass\n",
    "                batch_loss = self.criterion(predictions_batch, targets_batch).item()    # compute the loss\n",
    "                loss += batch_loss * inputs_batch.size(0)                               # accumulate the weighted loss\n",
    "                samples += inputs_batch.size(0)                                         # accumulate the number of samples\n",
    "        return loss / samples\n",
    "\n",
    "    def computeAccuracy(self, dataloader):\n",
    "        samples = 0\n",
    "        true_predictions = 0\n",
    "        self.eval() # set the model to evaluation mode\n",
    "        for inputs_batch, targets_batch in dataloader:\n",
    "            with torch.no_grad():\n",
    "                inputs_batch = inputs_batch.to(self.device)         # push inputs to GPU\n",
    "                targets_batch = targets_batch.to(self.device)       # push labels to GPU\n",
    "                predictions_batch = self.forward(inputs_batch)      # forward pass\n",
    "                true_predictions += torch.sum(torch.argmax(predictions_batch, dim=1) == targets_batch).item()\n",
    "                samples += targets_batch.shape[0]\n",
    "        return true_predictions / samples\n",
    "    \n",
    "    def fit(self, train_dataloader, optimizer=optim.Adam, epochs=30, lr=1e-4, \n",
    "        regularization=0.0, eval_dataloader=None, verbose=True, epch_print=1, \n",
    "        tolerance=1e-3, patience=5):\n",
    "\n",
    "        # Set the starting epoch\n",
    "        last_epoch = self.metrics['epochs'][-1] if self.metrics['epochs'] else 0\n",
    "        starting_epoch = last_epoch + 1\n",
    "    \n",
    "        # Set the optimizer\n",
    "        optimizer = optimizer(self.parameters(), lr=lr, weight_decay=regularization)\n",
    "\n",
    "        # Variables for early stopping\n",
    "        error_loss, error_accuracy = 1, 1\n",
    "        old_loss, old_accuracy = None, None\n",
    "        epochs_since_improvement = 0\n",
    "\n",
    "        # Start the training\n",
    "        start_time = time.time()\n",
    "        for i in range(epochs):\n",
    "            self.train()\n",
    "            for train_batch in train_dataloader:\n",
    "                self.trainBatch(train_batch[0], train_batch[1], optimizer)\n",
    "\n",
    "            # Evaluate the model\n",
    "            self.eval()\n",
    "            train_loss = self.computeLoss(train_dataloader)\n",
    "            train_acc = self.computeAccuracy(train_dataloader)\n",
    "            self.metrics['epochs'].append(starting_epoch + i)\n",
    "            self.metrics['loss']['train'].append(train_loss)\n",
    "            self.metrics['accuracy']['train'].append(train_acc)\n",
    "            if eval_dataloader:\n",
    "                eval_loss = self.computeLoss(eval_dataloader)\n",
    "                eval_acc = self.computeAccuracy(eval_dataloader)\n",
    "                self.metrics['loss']['eval'].append(eval_loss)\n",
    "                self.metrics['accuracy']['eval'].append(eval_acc)\n",
    "\n",
    "                # Check early stopping conditions on eval set\n",
    "                if i == 0:\n",
    "                    old_loss, old_accuracy = eval_loss, eval_acc\n",
    "                else:\n",
    "                    error_loss = abs(eval_loss - old_loss) / old_loss\n",
    "                    error_accuracy = abs(eval_acc - old_accuracy) / old_accuracy\n",
    "                    old_loss, old_accuracy = eval_loss, eval_acc\n",
    "            else:\n",
    "                # Check early stopping conditions on train set\n",
    "                if i == 0:\n",
    "                    old_loss, old_accuracy = train_loss, train_acc\n",
    "                else:\n",
    "                    error_loss = abs(train_loss - old_loss) / old_loss\n",
    "                    error_accuracy = abs(train_acc - old_accuracy) / old_accuracy\n",
    "                    old_loss, old_accuracy = train_loss, train_acc\n",
    "            \n",
    "            if (error_loss <= tolerance) and (error_accuracy <= tolerance):\n",
    "                epochs_since_improvement += 1\n",
    "            else:\n",
    "                epochs_since_improvement = 0\n",
    "            \n",
    "            # Print the progress\n",
    "            if verbose and (i + 1) % epch_print == 0:\n",
    "                eval_loss = eval_loss if eval_dataloader else 'N/A'\n",
    "                text = f\"Epoch {starting_epoch + i}/{starting_epoch + epochs}: \"\n",
    "                text += f\"Loss ({train_loss:.4g}, {eval_loss:.4g}) \\t \"\n",
    "                text += f\"Accuracy ({100*train_acc:.2f}%, {100*eval_acc:.2f}%)\"\n",
    "                print(text)\n",
    "\n",
    "            # Early stopping check\n",
    "            if epochs_since_improvement >= patience:\n",
    "                print(f\"Early stopping triggered after {i + 1} epochs.\")\n",
    "                break\n",
    "\n",
    "        self.metrics['time'] += time.time() - start_time\n",
    "\n",
    "    def size(self):\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "    def save(self, path: str=\"cnn_model_params.pth\"):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path: str=\"cnn_model_params.pth\"):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "        self.to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'conv_layers': [\n",
    "            {\n",
    "                'in_channels': 3,\n",
    "                'out_channels': 16,\n",
    "                'kernel_size': 3,\n",
    "                'stride': 1,\n",
    "                'padding': 1,\n",
    "                'padding_mode': 'zeros',\n",
    "                'pool_kernel_size': 2,\n",
    "                'pool_stride': 2,\n",
    "                'pool_padding': 0\n",
    "            },\n",
    "            {\n",
    "                'in_channels': 16,\n",
    "                'out_channels': 32,\n",
    "                'kernel_size': 3,\n",
    "                'stride': 1,\n",
    "                'padding': 1,\n",
    "                'padding_mode': 'zeros',\n",
    "                'pool_kernel_size': 2,\n",
    "                'pool_stride': 2,\n",
    "                'pool_padding': 0\n",
    "            },\n",
    "            {\n",
    "                'in_channels': 32,\n",
    "                'out_channels': 64,\n",
    "                'kernel_size': 3,\n",
    "                'stride': 1,\n",
    "                'padding': 1,\n",
    "                'padding_mode': 'zeros',\n",
    "                'pool_kernel_size': 2,\n",
    "                'pool_stride': 2,\n",
    "                'pool_padding': 0\n",
    "            },\n",
    "            {\n",
    "                'in_channels': 64,\n",
    "                'out_channels': 128,\n",
    "                'kernel_size': 3,\n",
    "                'stride': 1,\n",
    "                'padding': 1,\n",
    "                'padding_mode': 'zeros',\n",
    "                'pool_kernel_size': 2,\n",
    "                'pool_stride': 2,\n",
    "                'pool_padding': 0\n",
    "            }\n",
    "        ],\n",
    "        'full_layers': [512],\n",
    "        'n_classes': 2,\n",
    "        'dropout_rate': 0.2,\n",
    "        'activation': nn.ReLU(),\n",
    "        'criterion': nn.CrossEntropyLoss(),\n",
    "        'init_type': 'xavier',\n",
    "        'device': 'cpu'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "conv_blocks = []\n",
    "for conv_layer in parameters['conv_layers']:\n",
    "    conv_block = ConvolutionalBlock(**conv_layer)\n",
    "    conv_blocks.append(conv_block)\n",
    "model = CNN(conv_blocks=conv_blocks, \n",
    "            image_shape=(3, width, height),\n",
    "            n_classes=parameters['n_classes'],\n",
    "            out_neurons=parameters['full_layers'][0],\n",
    "            activation=parameters['activation'], \n",
    "            criterion=parameters['criterion'], \n",
    "            dropout_rate=parameters['dropout_rate'],\n",
    "            init_type=parameters['init_type'],\n",
    "            device=parameters['device'])\n",
    "model = model.to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fit parameters.\n",
    "optimizer = optim.AdamW\n",
    "epochs = 30\n",
    "lr = 1e-4\n",
    "regularization = 1e-5\n",
    "verbose = True\n",
    "epch_print = 5\n",
    "tolerance = 1e-3\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_loader, optimizer=optimizer, epochs=epochs, lr=lr, regularization=regularization, \n",
    "          eval_dataloader=valid_loader, verbose=verbose, epch_print=epch_print, tolerance=tolerance, \n",
    "          patience=patience)\n",
    "model.save(\"cat_dog.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot loss\n",
    "axs[0].plot(model.metrics['epochs'], model.metrics['loss']['train'], label=f\"Training\")\n",
    "axs[0].plot(model.metrics['epochs'], model.metrics['loss']['eval'], label=f\"Validation\")\n",
    "axs[0].set_title(\"Cats vs Dogs - Loss\")\n",
    "axs[0].set_xlabel(\"Epochs\")\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].legend(loc='best')\n",
    "axs[0].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Plot accuracy\n",
    "axs[1].plot(model.metrics['epochs'], model.metrics['accuracy']['train'], label=f\"Training\")\n",
    "axs[1].plot(model.metrics['epochs'], model.metrics['accuracy']['eval'], label=f\"Validation\")\n",
    "axs[1].set_title(\"Cats vs Dogs - Accuracy\")\n",
    "axs[1].set_xlabel(\"Epochs\")\n",
    "axs[1].set_ylabel(\"Accuracy\")\n",
    "axs[1].legend(loc='best')\n",
    "axs[1].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"cat_dog_results.png\", dpi=300, facecolor='w', edgecolor='w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 733,
     "status": "ok",
     "timestamp": 1714220230733,
     "user": {
      "displayName": "Juan Ignacio Cavalieri",
      "userId": "15252118238119694163"
     },
     "user_tz": 180
    },
    "id": "-WtAgm6kR_vw",
    "outputId": "3e07b39d-03f2-4448-935a-adc49a80827e"
   },
   "outputs": [],
   "source": [
    "class ConvModel(torch.nn.Module):\n",
    "    def __init__(self, output_units):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding='same')\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding='same')\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding='same')\n",
    "        self.pool3 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv4 = torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding='same')\n",
    "        self.pool4 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = torch.nn.Linear(in_features=10368, out_features=512)\n",
    "        self.fc2 = torch.nn.Linear(in_features=512, out_features=output_units)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(torch.relu(self.conv1(x)))\n",
    "        x = self.pool2(torch.relu(self.conv2(x)))\n",
    "        x = self.pool3(torch.relu(self.conv3(x)))\n",
    "        x = self.pool4(torch.relu(self.conv4(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "conv_model = ConvModel(CANTIDAD_CLASES)\n",
    "\n",
    "# Si hay una GPU disponible muevo el modelo allí para aprovechar ese recurso\n",
    "if torch.cuda.is_available():\n",
    "    conv_model.to(\"cuda\")\n",
    "\n",
    "torchsummary.summary(conv_model, (3, ANCHO_IMAGENES, ALTO_IMAGENES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_9CcYFFxqH6"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, metric, data, epochs, tb_writer=None):\n",
    "\n",
    "    train_loader = data[\"train\"]\n",
    "    valid_loader = data[\"valid\"]\n",
    "\n",
    "    train_writer = tb_writer[\"train\"]\n",
    "    valid_writer = tb_writer[\"valid\"]\n",
    "\n",
    "    if tb_writer:\n",
    "        train_writer.add_graph(model, torch.zeros((1, 3, data[\"image_width\"], data[\"image_height\"])))\n",
    "        valid_writer.add_graph(model, torch.zeros((1, 3, data[\"image_width\"], data[\"image_height\"])))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.to(\"cuda\")\n",
    "        metric.to(\"cuda\")\n",
    "\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    valid_loss = []\n",
    "    valid_acc = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Pongo el modelo en modo entrenamiento\n",
    "        model.train()\n",
    "\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_train_accuracy = 0.0\n",
    "\n",
    "        for train_data, train_target in train_loader:\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                train_data = train_data.to(\"cuda\")\n",
    "                train_target = train_target.to(\"cuda\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(train_data.float())\n",
    "            loss = criterion(output, train_target)\n",
    "            epoch_train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            accuracy = metric(output, train_target)\n",
    "            epoch_train_accuracy += accuracy.item()\n",
    "\n",
    "        epoch_train_loss = epoch_train_loss / len(train_loader)\n",
    "        epoch_train_accuracy = epoch_train_accuracy / len(train_loader)\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        train_acc.append(epoch_train_accuracy)\n",
    "\n",
    "        # Pongo el modelo en modo testeo\n",
    "        model.eval()\n",
    "\n",
    "        epoch_valid_loss = 0.0\n",
    "        epoch_valid_accuracy = 0.0\n",
    "\n",
    "        for valid_data, valid_target in valid_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                valid_data = valid_data.to(\"cuda\")\n",
    "                valid_target = valid_target.to(\"cuda\")\n",
    "\n",
    "            output = model(valid_data.float())\n",
    "            epoch_valid_loss += criterion(output, valid_target).item()\n",
    "            epoch_valid_accuracy += metric(output, valid_target).item()\n",
    "\n",
    "        epoch_valid_loss = epoch_valid_loss / len(valid_loader)\n",
    "        epoch_valid_accuracy = epoch_valid_accuracy / len(valid_loader)\n",
    "        valid_loss.append(epoch_valid_loss)\n",
    "        valid_acc.append(epoch_valid_accuracy)\n",
    "\n",
    "        print(\"Epoch: {}/{} - Train loss {:.6f} - Train Accuracy {:.6f} - Valid Loss {:.6f} - Valid Accuracy {:.6f}\".format(\n",
    "        epoch+1, epochs, epoch_train_loss, epoch_train_accuracy, epoch_valid_loss, epoch_valid_accuracy))\n",
    "\n",
    "        if tb_writer:\n",
    "            train_writer.add_scalar(\"loss\", epoch_train_loss, epoch)\n",
    "            valid_writer.add_scalar(\"loss\", epoch_valid_loss, epoch)\n",
    "            train_writer.add_scalar(\"accuracy\", epoch_train_accuracy, epoch)\n",
    "            valid_writer.add_scalar(\"accuracy\", epoch_valid_accuracy, epoch)\n",
    "            train_writer.flush()\n",
    "            valid_writer.flush()\n",
    "\n",
    "    history = {}\n",
    "    history[\"train_loss\"] = train_loss\n",
    "    history[\"train_acc\"] = train_acc\n",
    "    history[\"valid_loss\"] = valid_loss\n",
    "    history[\"valid_acc\"] = valid_acc\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 190950,
     "status": "ok",
     "timestamp": 1714220421679,
     "user": {
      "displayName": "Juan Ignacio Cavalieri",
      "userId": "15252118238119694163"
     },
     "user_tz": 180
    },
    "id": "Z2X0ZdYNxqH6",
    "outputId": "04659119-f149-446d-d1a8-ab16e446bc8b"
   },
   "outputs": [],
   "source": [
    "noaug_conv_model = ConvModel(CANTIDAD_CLASES)\n",
    "noaug_optimizer = torch.optim.Adam(noaug_conv_model.parameters(), lr=0.0001)\n",
    "noaug_loss = torch.nn.CrossEntropyLoss()\n",
    "noaug_metric = torchmetrics.Accuracy(task='multiclass', num_classes=CANTIDAD_CLASES)\n",
    "noaug_data = {\"train\": train_loader, \"valid\": valid_loader, \"image_width\": ANCHO_IMAGENES, \"image_height\": ALTO_IMAGENES}\n",
    "\n",
    "noaug_writer = {\"train\": SummaryWriter(log_dir=\"data_aug/noaug_train\"),\n",
    "                \"valid\": SummaryWriter(log_dir=\"data_aug/noaug_valid\")}\n",
    "\n",
    "history = train(noaug_conv_model,\n",
    "                noaug_optimizer,\n",
    "                noaug_loss,\n",
    "                noaug_metric,\n",
    "                noaug_data,\n",
    "                20,\n",
    "                noaug_writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-fuvze5dgm7"
   },
   "source": [
    "Realizo gráficas del resultado del entrenamiento para visualizar el comportamiento de las métricas a lo largo de las epocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 871
    },
    "executionInfo": {
     "elapsed": 3861,
     "status": "ok",
     "timestamp": 1714220425524,
     "user": {
      "displayName": "Juan Ignacio Cavalieri",
      "userId": "15252118238119694163"
     },
     "user_tz": 180
    },
    "id": "lBFgC18faq-q",
    "outputId": "d0d37f2e-692e-42ee-e7f2-24dcf8393f8e"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "axs[0].plot(history[\"train_loss\"])\n",
    "axs[0].plot(history[\"valid_loss\"])\n",
    "axs[0].title.set_text('Error de Entrenamiento vs Validación')\n",
    "axs[0].legend(['Train', 'Valid'])\n",
    "\n",
    "axs[1].plot(history[\"train_acc\"])\n",
    "axs[1].plot(history[\"valid_acc\"])\n",
    "axs[1].title.set_text('Accuracy de Entrenamiento vs Validación')\n",
    "axs[1].legend(['Train', 'Valid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xESj7o4YBl5"
   },
   "source": [
    "Su puede observar una clara tendencia al sobreentrenamiento del modelo, el cual es debido a, entre otras cosas, la poca cantidad de datos de entrenamiento utilizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xrQcjrmARne"
   },
   "source": [
    "---\n",
    "## Aplicar Data Augmentation\n",
    "\n",
    "Para aplicar Data Augmentation sobre los datos vamos a utilizar la misma composición de transformaciones que ya veniamos utilizando. Allí podemos agregar una serie de funciones listadas [`aquí`](https://pytorch.org/vision/stable/transforms.html). Para ver ejemplos de dichas transformaciones ver [este](https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#sphx-glr-auto-examples-plot-transforms-py) link.\n",
    "\n",
    "Ademas de las transformaciones implementadas dentro del modulo `torchvision` de Pytorch, podemos optar por utilizar librerias externas para dicho proposito e integrar sus transformaciones en el pipeline de entrenamiento de Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1Wv3Ozhd2DC"
   },
   "outputs": [],
   "source": [
    "aug_data_transforms = torchvision.transforms.Compose([\n",
    "                        torchvision.transforms.Resize(size=(ANCHO_IMAGENES, ALTO_IMAGENES)),\n",
    "                        torchvision.transforms.RandomHorizontalFlip(0.5),\n",
    "                        torchvision.transforms.RandomResizedCrop(size=(ANCHO_IMAGENES, ALTO_IMAGENES), scale=(0.5, 1.0)),\n",
    "                        torchvision.transforms.ColorJitter(saturation=0.1, hue=0.1),\n",
    "                        torchvision.transforms.ToTensor()\n",
    "                      ])\n",
    "\n",
    "data_transforms = torchvision.transforms.Compose([\n",
    "                    torchvision.transforms.Resize(size=(ANCHO_IMAGENES, ALTO_IMAGENES)),\n",
    "                    torchvision.transforms.ToTensor()\n",
    "                  ])\n",
    "\n",
    "aug_train_set = torchvision.datasets.ImageFolder(root='./dataset_perros_y_gatos/train', transform=aug_data_transforms)\n",
    "aug_valid_set = torchvision.datasets.ImageFolder(root='./dataset_perros_y_gatos/validation', transform=data_transforms)\n",
    "\n",
    "aug_train_loader = torch.utils.data.DataLoader(aug_train_set, batch_size=32, shuffle=True)\n",
    "aug_valid_loader = torch.utils.data.DataLoader(aug_valid_set, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYOyV-AbeYhS"
   },
   "source": [
    "Podemos visualizar el resultado de aplicar dichas transformaciones sobre las imágenes de nuestro dataset. Para ello debemos revertir la normalización aplicada por las transformaciones. Aquí el metodo [`permute`](https://pytorch.org/docs/stable/generated/torch.permute.html#torch.permute) nos permite reordenar las dimensiones del tensor de (3, 150, 150) a (150, 150, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "executionInfo": {
     "elapsed": 3701,
     "status": "ok",
     "timestamp": 1714220429216,
     "user": {
      "displayName": "Juan Ignacio Cavalieri",
      "userId": "15252118238119694163"
     },
     "user_tz": 180
    },
    "id": "mMzH_oqQf1wD",
    "outputId": "5e29ab55-469c-458d-b688-91828557cba8"
   },
   "outputs": [],
   "source": [
    "images_ids = np.random.randint(low=0, high=len(train_set), size=4)\n",
    "\n",
    "# Ploteo las imagenes sin augmentacion\n",
    "\n",
    "fig, rows = plt.subplots(nrows=1, ncols=4, figsize=(18, 18))\n",
    "\n",
    "for id, row in enumerate(rows):\n",
    "    row.imshow(train_set[images_ids[id]][0].permute(1, 2, 0))\n",
    "    row.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Ploteo las mismas imagenes con augmentacion\n",
    "\n",
    "fig, rows = plt.subplots(nrows=1, ncols=4, figsize=(18, 18))\n",
    "\n",
    "for id, row in enumerate(rows):\n",
    "    row.imshow(aug_train_set[images_ids[id]][0].permute(1, 2, 0))\n",
    "    row.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ljmppdfe10k"
   },
   "source": [
    "Si ahora, repito el proceso de entrenamiento, utilizando la misma arquitectura de red neuronal del caso anterior, pero pasandole datos sobre los que realizo las perturbaciones antes definidas, mi entrenamiento deberia ser más estable aunque un poco mas lento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 769358,
     "status": "ok",
     "timestamp": 1714221198572,
     "user": {
      "displayName": "Juan Ignacio Cavalieri",
      "userId": "15252118238119694163"
     },
     "user_tz": 180
    },
    "id": "JaR8A7Gk0-i8",
    "outputId": "1813ffba-7109-459d-db52-63fc115d860e"
   },
   "outputs": [],
   "source": [
    "aug_conv_model = ConvModel(CANTIDAD_CLASES)\n",
    "aug_optimizer = torch.optim.Adam(aug_conv_model.parameters(), lr=0.0001)\n",
    "aug_loss = torch.nn.CrossEntropyLoss()\n",
    "aug_metric = torchmetrics.Accuracy(task='multiclass', num_classes=CANTIDAD_CLASES)\n",
    "aug_data = {\"train\": aug_train_loader, \"valid\": aug_valid_loader, \"image_width\": ANCHO_IMAGENES, \"image_height\": ALTO_IMAGENES}\n",
    "\n",
    "aug_writer = {\"train\": SummaryWriter(log_dir=\"data_aug/aug_train\"),\n",
    "              \"valid\": SummaryWriter(log_dir=\"data_aug/aug_valid\")}\n",
    "\n",
    "history = train(aug_conv_model,\n",
    "                aug_optimizer,\n",
    "                aug_loss,\n",
    "                aug_metric,\n",
    "                aug_data,\n",
    "                50,\n",
    "                aug_writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 871
    },
    "executionInfo": {
     "elapsed": 1657,
     "status": "ok",
     "timestamp": 1714221200193,
     "user": {
      "displayName": "Juan Ignacio Cavalieri",
      "userId": "15252118238119694163"
     },
     "user_tz": 180
    },
    "id": "IabLfLVZnfvT",
    "outputId": "64513cb5-d99a-40a4-9b98-217f678770d0"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
    "\n",
    "axs[0].plot(history[\"train_loss\"])\n",
    "axs[0].plot(history[\"valid_loss\"])\n",
    "axs[0].title.set_text('Error de Entrenamiento vs Validación')\n",
    "axs[0].legend(['Train', 'Valid'])\n",
    "\n",
    "axs[1].plot(history[\"train_acc\"])\n",
    "axs[1].plot(history[\"valid_acc\"])\n",
    "axs[1].title.set_text('Accuracy de Entrenamiento vs Validación')\n",
    "axs[1].legend(['Train', 'Valid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cr3Xsk-mIa8f"
   },
   "source": [
    "---\n",
    "## TensorBoard\n",
    "\n",
    "Otra forma de visualizar los resultados del entrenamiento de nuestra red es mediante la herramienta TensorBoard, la cual forma parte del framework de Tensorflow. Esta herramienta nos permite ver graficas interactivas de la evolución de las distintas metricas a lo largo de las epocas o las iteraciones de entrenamiento, así como también un grafo de las conexiones que componen nuestro modelo, entre otras cosas."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "6a7e264b0185234a6d090a42ff6d01e38825180e16d17b7c5c45b22f8dc26b79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
